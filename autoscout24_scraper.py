#!/usr/bin/env python3
"""
AutoScout24 Scraper Principal - Version Autonome et Am√©lior√©e
G√©n√®re une liste de mod√®les par marque depuis AutoScout24.fr
Capable d'extraire automatiquement les marques si le fichier n'existe pas

Usage:
    python autoscout24_scraper.py                    # Scrape toutes les marques
    python autoscout24_scraper.py --test            # Test sur 20 marques
    python autoscout24_scraper.py --headless=False  # Voir le navigateur
    python autoscout24_scraper.py --max-brands 50   # Limiter √† 50 marques
"""

import argparse
import json
import time
import random
import logging
import sys
import re
from datetime import datetime, timezone
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException

# Configuration logging avec emojis
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('scraper.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class AutoScout24Scraper:
    """Scraper AutoScout24 autonome et robuste."""
    
    def __init__(self, headless=True):
        self.base_url = "https://www.autoscout24.fr"
        self.brand_models_data = {}
        self.setup_driver(headless)
        self.load_brands_from_json()
        
    def setup_driver(self, headless=True):
        """Configure le driver Selenium avec des options optimis√©es."""
        try:
            chrome_options = Options()
            if headless:
                chrome_options.add_argument("--headless=new")  # Nouveau mode headless
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--window-size=1920,1080")
            chrome_options.add_argument("--disable-blink-features=AutomationControlled")
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
            
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.implicitly_wait(10)
            logger.info("‚úÖ Driver Selenium configur√©")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur configuration driver: {e}")
            raise
    
    def load_brands_from_json(self):
        """Charge la liste des marques depuis le fichier JSON ou l'extrait si n√©cessaire."""
        try:
            brands_file = Path("data/as24_brands_for_scraping.json")
            if brands_file.exists():
                with open(brands_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.brands_list = data["brands"]
                logger.info(f"üìã Charg√© {len(self.brands_list)} marques depuis as24_brands_for_scraping.json")
                return True
            else:
                logger.warning("‚ö†Ô∏è Fichier as24_brands_for_scraping.json non trouv√©")
                logger.info("üîÑ Extraction automatique des marques depuis AutoScout24...")
                if self.extract_brands_from_autoscout24():
                    # Recharger apr√®s extraction
                    with open(brands_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        self.brands_list = data["brands"]
                    logger.info(f"‚úÖ Extraction r√©ussie: {len(self.brands_list)} marques")
                    return True
                else:
                    logger.error("‚ùå Impossible d'extraire les marques")
                    self.brands_list = []
                    return False
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement des marques: {e}")
            return False
    
    def extract_brands_from_autoscout24(self):
        """Extrait automatiquement les marques depuis AutoScout24."""
        try:
            logger.info("üîç Extraction des marques depuis AutoScout24...")
            
            # S'assurer qu'on est sur la page d'accueil
            if not self.navigate_to_homepage():
                return False
            
            # Chercher le s√©lecteur des marques
            make_selectors = [
                "select[name='make']",
                "select[id='make']",
                "select[aria-label*='marque']",
                "select[aria-label*='brand']"
            ]
            
            make_select = None
            for selector in make_selectors:
                try:
                    make_select = self.driver.find_element(By.CSS_SELECTOR, selector)
                    logger.info(f"‚úÖ Menu marques trouv√© avec s√©lecteur: {selector}")
                    break
                except NoSuchElementException:
                    continue
            
            if not make_select:
                logger.error("‚ùå Menu d√©roulant des marques non trouv√©")
                return False
            
            # Extraire toutes les options
            options = make_select.find_elements(By.TAG_NAME, "option")
            logger.info(f"üîç Trouv√© {len(options)} options dans le menu")
            
            brands_data = {}
            excluded_terms = [
                'top marques', 'autres marques', 'make', 'marque', 
                'tous', 'selectionner', 'toutes', 'ÂÖ®ÈÉ®', 'ÂÖ®ÈÉ®ÂìÅÁâå'
            ]
            
            for option in options:
                try:
                    brand_name = option.text.strip()
                    brand_value = option.get_attribute("value")
                    
                    # Ignorer les options par d√©faut et les sections
                    if (brand_name and brand_value and 
                        brand_name not in ['Marque', 'Tous', 'S√©lectionner', 'Make'] and
                        not any(term in brand_name.lower() for term in excluded_terms) and
                        brand_value != ''):
                        brands_data[brand_name] = brand_value
                        
                except Exception as e:
                    logger.debug(f"Erreur lors de l'extraction d'une option: {e}")
                    continue
            
            if not brands_data:
                logger.error("‚ùå Aucune marque trouv√©e")
                return False
            
            # Convertir en format attendu par le scraper
            self.brands_list = [{"name": name, "id": value} for name, value in brands_data.items()]
            
            # Sauvegarder le fichier brands_for_scraping.json
            output_data = {
                "metadata": {
                    "extracted_at": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "source": "AutoScout24.fr Auto Extraction",
                    "method": "selenium_dropdown_analysis",
                    "total_brands": len(brands_data)
                },
                "brands": self.brands_list
            }

            brands_file = Path("data/as24_brands_for_scraping.json")
            brands_file.parent.mkdir(parents=True, exist_ok=True)
            with open(brands_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)

            # G√©n√©rer aussi la version Markdown lisible
            self.generate_brands_markdown_version(output_data, str(brands_file))

            logger.info(f"üíæ Fichier as24_brands_for_scraping.json cr√©√©: {len(brands_data)} marques")
            
            # Comparer avec la version pr√©c√©dente s'il y en a une
            self.compare_with_previous_version()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'extraction des marques: {e}")
            return False
    
    def compare_with_previous_version(self):
        """Compare avec la version pr√©c√©dente et affiche les changements."""
        try:
            # Chercher le fichier de donn√©es le plus r√©cent
            data_dir = Path("data")
            version_pattern = r"as24_scraped_models_(\d{8}_\d{6})\.json"
            
            versions = []
            for file in data_dir.glob("as24_scraped_models_*.json"):
                match = re.search(version_pattern, file.name)
                if match:
                    timestamp = match.group(1)
                    versions.append((timestamp, file))
            
            if not versions:
                logger.info("‚ÑπÔ∏è Aucune version pr√©c√©dente trouv√©e")
                return
            
            # Trouver la version la plus r√©cente
            versions.sort(key=lambda x: x[0])
            previous_file = versions[-1][1]
            
            logger.info(f"üîÑ Comparaison avec la version pr√©c√©dente: {previous_file.name}")
            
            # Charger la version pr√©c√©dente
            with open(previous_file, 'r', encoding='utf-8') as f:
                previous_data = json.load(f)
            
            # Comparer les marques
            previous_brands = set(previous_data["brands_models"].keys())
            current_brands = set(brand["name"] for brand in self.brands_list)
            
            new_brands = current_brands - previous_brands
            removed_brands = previous_brands - current_brands
            
            # Afficher le rapport de changements
            logger.info("üìä RAPPORT DE VERSIONING:")
            logger.info(f"   ‚Ä¢ Marques pr√©c√©dentes: {len(previous_brands)}")
            logger.info(f"   ‚Ä¢ Marques actuelles: {len(current_brands)}")
            logger.info(f"   ‚Ä¢ Changement: {len(current_brands) - len(previous_brands):+d}")
            
            if new_brands:
                logger.info(f"   ‚Ä¢ NOUVELLES MARQUES ({len(new_brands)}):")
                for brand in sorted(new_brands):
                    logger.info(f"     + {brand}")
            
            if removed_brands:
                logger.info(f"   ‚Ä¢ MARQUES SUPPRIM√âES ({len(removed_brands)}):")
                for brand in sorted(removed_brands):
                    logger.info(f"     - {brand}")
            
            if not new_brands and not removed_brands:
                logger.info("   ‚úÖ Aucune marque ajout√©e ou supprim√©e")
            
        except Exception as e:
            logger.debug(f"Erreur lors de la comparaison: {e}")
    
    def navigate_to_homepage(self):
        """Navigue vers la page d'accueil et attend le chargement complet."""
        try:
            logger.info(f"üåê Navigation vers: {self.base_url}")
            self.driver.get(self.base_url)
            
            # Attendre que les √©l√©ments critiques soient pr√©sents
            WebDriverWait(self.driver, 20).until(
                EC.any_of(
                    EC.presence_of_element_located((By.TAG_NAME, "body")),
                    EC.presence_of_element_located((By.CSS_SELECTOR, "select[name='make']")),
                    EC.presence_of_element_located((By.CSS_SELECTOR, "select[id='make']"))
                )
            )
            
            # Attendre le chargement des menus d√©roulants
            time.sleep(3)
            logger.info("‚úÖ Page d'accueil charg√©e")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur navigation homepage: {e}")
            return False
    
    def select_brand_in_menu(self, brand_name, brand_id):
        """S√©lectionne une marque dans le menu d√©roulant."""
        try:
            make_selectors = [
                "select[name='make']",
                "select[id='make']",
                ".make-select"
            ]
            
            make_select = None
            for selector in make_selectors:
                try:
                    make_select = self.driver.find_element(By.CSS_SELECTOR, selector)
                    logger.debug(f"‚úÖ Menu marques trouv√© avec: {selector}")
                    break
                except NoSuchElementException:
                    continue
            
            if not make_select:
                logger.error("‚ùå Menu marques non trouv√©")
                return False
            
            select = Select(make_select)
            select.select_by_value(brand_id)
            
            # Attendre que la page se mette √† jour
            time.sleep(2)
            logger.debug(f"‚úÖ Marque '{brand_name}' s√©lectionn√©e (ID: {brand_id})")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur s√©lection marque {brand_name}: {e}")
            return False
    
    def get_model_menu_options(self):
        """R√©cup√®re les options du menu d√©roulant des mod√®les."""
        try:
            model_selectors = [
                "select[name='model']",
                "select[id='model']",
                "select[aria-label*='mod√®le']",
                "select[aria-label*='model']",
                ".model-select",
                "#model-select"
            ]
            
            for selector in model_selectors:
                try:
                    model_select = self.driver.find_element(By.CSS_SELECTOR, selector)
                    
                    WebDriverWait(self.driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, f"{selector} option"))
                    )
                    
                    options = model_select.find_elements(By.TAG_NAME, "option")
                    models = []
                    
                    logger.debug(f"üîç Menu mod√®les: {selector}, {len(options)} options")
                    
                    for option in options:
                        model_name = option.text.strip()
                        if model_name and model_name not in ['Mod√®le', 'Tous', 'S√©lectionner', 'Model']:
                            models.append(model_name)
                    
                    if models:
                        logger.debug(f"‚úÖ {len(models)} mod√®les trouv√©s")
                        return models
                    
                except (NoSuchElementException, TimeoutException):
                    continue
            
            logger.warning("‚ö†Ô∏è Menu mod√®les non trouv√© ou vide")
            return []
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration mod√®les: {e}")
            return []
    
    def scrape_brand_models(self, brand_name, brand_id):
        """Scrape les mod√®les d'une marque sp√©cifique."""
        try:
            if not self.select_brand_in_menu(brand_name, brand_id):
                return []
            
            models = self.get_model_menu_options()
            
            if models:
                logger.info(f"‚úÖ {brand_name}: {len(models)} mod√®les r√©cup√©r√©s")
                return models
            else:
                logger.warning(f"‚ö†Ô∏è {brand_name}: Aucun mod√®le trouv√©")
                return []
                
        except Exception as e:
            logger.error(f"‚ùå Erreur scraping {brand_name}: {e}")
            return []
    
    def compare_model_changes_with_previous(self, brand_name, new_models):
        """Compare les mod√®les d'une marque avec la version pr√©c√©dente."""
        try:
            # Chercher le fichier de donn√©es le plus r√©cent
            data_dir = Path("data")
            version_pattern = r"as24_scraped_models_(\d{8}_\d{6})\.json"
            
            versions = []
            for file in data_dir.glob("as24_scraped_models_*.json"):
                match = re.search(version_pattern, file.name)
                if match:
                    timestamp = match.group(1)
                    versions.append((timestamp, file))
            
            if not versions:
                return None
            
            # Trouver la version la plus r√©cente
            versions.sort(key=lambda x: x[0])
            previous_file = versions[-1][1]
            
            # Charger la version pr√©c√©dente
            with open(previous_file, 'r', encoding='utf-8') as f:
                previous_data = json.load(f)
            
            # Comparer les mod√®les de cette marque
            previous_models = set(previous_data["brands_models"].get(brand_name, []))
            current_models = set(new_models)
            
            new_models_for_brand = current_models - previous_models
            removed_models_for_brand = previous_models - current_models
            
            if new_models_for_brand or removed_models_for_brand:
                logger.info(f"   üîÑ Changements mod√®les pour {brand_name}:")
                if new_models_for_brand:
                    logger.info(f"     + Nouveaux: {', '.join(sorted(new_models_for_brand))}")
                if removed_models_for_brand:
                    logger.info(f"     - Supprim√©s: {', '.join(sorted(removed_models_for_brand))}")
            
            return {
                "new_models": list(new_models_for_brand),
                "removed_models": list(removed_models_for_brand),
                "total_changes": len(new_models_for_brand) + len(removed_models_for_brand)
            }
            
        except Exception as e:
            logger.debug(f"Erreur lors de la comparaison des mod√®les pour {brand_name}: {e}")
            return None
    
    def update_execution_history(self, output_file, versioning_data=None):
        """Met √† jour l'historique des ex√©cutions en format Markdown."""
        try:
            history_file = Path("docs/execution_history.md")
            history_file.parent.mkdir(parents=True, exist_ok=True)
            
            # G√©n√©rer les donn√©es de versioning pour l'historique
            execution_data = self.generate_execution_data(output_file, versioning_data)
            
            # Lire l'historique existant ou cr√©er un nouveau
            if history_file.exists():
                with open(history_file, 'r', encoding='utf-8') as f:
                    content = f.read()
            else:
                content = self.generate_history_header()
            
            # Ajouter la nouvelle entr√©e au D√âBUT (apr√®s l'en-t√™te)
            entry = self.format_execution_entry(execution_data)
            
            if content.startswith("#"):
                lines = content.split('\n')
                header_end = 0
                
                # CORRECTION: Trouver la vraie fin de l'en-t√™te (apr√®s les "---" de s√©paration)
                for i, line in enumerate(lines):
                    if line.strip() == '---' and i > 5:  # Il doit y avoir du contenu avant
                        header_end = i + 1  # +1 pour passer la ligne "---"
                        break
                
                if header_end > 0:
                    # INS√âRER au d√©but de la section historique (apr√®s l'en-t√™te)
                    content = '\n'.join(lines[:header_end]) + entry + '\n' + '\n'.join(lines[header_end:])
                else:
                    # Si on ne trouve pas la s√©paration, ajouter apr√®s l'en-t√™te existant
                    content += '\n' + entry
            else:
                content = self.generate_history_header() + entry
            
            # Sauvegarder
            with open(history_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"üìù Historique mis √† jour: {history_file}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la mise √† jour de l'historique: {e}")
    
    def generate_history_header(self):
        """G√©n√®re l'en-t√™te du fichier d'historique."""
        return """# üìä AutoScout24 Scraper - Historique des Ex√©cutions

Ce fichier contient l'historique complet des ex√©cutions du scraper avec les informations de versioning.

## üìã Structure
- **Timestamp** : Date et heure d'ex√©cution
- **Fichier de donn√©es** : Lien vers le fichier JSON g√©n√©r√©
- **Statistiques** : Nombre de marques et mod√®les trait√©s
- **Versioning** : Comparaison avec la version pr√©c√©dente
- **Changements** : D√©tail des nouvelles marques, marques supprim√©es et mod√®les modifi√©s

---

"""
    
    def generate_execution_data(self, output_file, versioning_data):
        """G√©n√®re les donn√©es de l'ex√©cution pour l'historique."""
        # Charger le fichier de donn√©es pour r√©cup√©rer les m√©tadonn√©es
        with open(output_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        metadata = data["metadata"]
        
        execution_data = {
            "timestamp": metadata["scraped_at"],
            "file": output_file,
            "file_name": Path(output_file).name,
            "total_brands": metadata["total_brands"],
            "total_models": metadata["total_models"],
            "brands_with_models": metadata["brands_with_models"],
            "brands_without_models": metadata["brands_without_models"],
            "scraper_version": metadata["scraper_version"],
            "method": metadata["method"],
            "versioning": versioning_data or {},
            "brands_data": data["brands_models"]
        }
        
        return execution_data
    
    def format_execution_entry(self, execution_data):
        """Formate une entr√©e d'ex√©cution pour l'historique Markdown."""
        timestamp = execution_data["timestamp"]
        file_name = execution_data["file_name"]
        
        # Formater la date pour l'affichage
        try:
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            display_date = dt.strftime("%d/%m/%Y √† %H:%M")
        except:
            display_date = timestamp
        
        # Construire l'entr√©e Markdown - STRUCTURE CLAIRE ET S√âPAR√âE
        entry = f"\n## üìÖ {display_date}\n\n"
        entry += f"**üìÑ Fichier de donn√©es** : `{file_name}`  \n"
        entry += f"**üöÄ Scraper** : {execution_data['scraper_version']}  \n"
        entry += f"**üîß M√©thode** : {execution_data['method']}  \n\n"
        
        entry += "### üìä Statistiques\n\n"
        entry += f"- **Marques trait√©es** : {execution_data['total_brands']}\n"
        entry += f"- **‚úÖ Marques avec mod√®les** : {execution_data['brands_with_models']}\n"
        entry += f"- **‚ùå Marques sans mod√®les** : {execution_data['brands_without_models']}\n"
        entry += f"- **üè∑Ô∏è Total mod√®les** : {execution_data['total_models']}\n\n"
        
        # Versioning d√©taill√© seulement s'il y a des changements
        if execution_data.get('versioning') and any(execution_data['versioning'].values()):
            entry += "### üîÑ Versioning vs Version Pr√©c√©dente\n\n"
            
            if execution_data['versioning'].get('brand_changes', 0) != 0:
                entry += f"**üìã Marques** : {execution_data['versioning']['previous_brands']} ‚Üí {execution_data['versioning']['current_brands']} ({execution_data['versioning']['brand_changes']:+d})\n"
            
            if execution_data['versioning'].get('model_changes', 0) != 0:
                entry += f"**üè∑Ô∏è Mod√®les** : {execution_data['versioning']['previous_models']} ‚Üí {execution_data['versioning']['current_models']} ({execution_data['versioning']['model_changes']:+d})\n\n"
            
            # Nouvelles marques
            if execution_data['versioning'].get('new_brands'):
                entry += f"**‚ûï Nouvelles marques ({len(execution_data['versioning']['new_brands'])})** :\n"
                for brand in execution_data['versioning']['new_brands']:
                    model_count = len(execution_data['brands_data'].get(brand, []))
                    entry += f"- {brand} ({model_count} mod√®les)\n"
                entry += "\n"
            
            # Marques supprim√©es
            if execution_data['versioning'].get('removed_brands'):
                entry += f"**‚ûñ Marques supprim√©es ({len(execution_data['versioning']['removed_brands'])})** :\n"
                for brand in execution_data['versioning']['removed_brands']:
                    entry += f"- {brand}\n"
                entry += "\n"
            
            # Marques avec changements significatifs
            if execution_data['versioning'].get('significant_changes'):
                entry += f"**üîÑ Marques avec changements significatifs ({len(execution_data['versioning']['significant_changes'])})** :\n"
                for change in execution_data['versioning']['significant_changes'][:5]:  # Limiter √† 5
                    entry += f"- {change['brand']} : {change['previous_count']} ‚Üí {change['current_count']} mod√®les\n"
                if len(execution_data['versioning']['significant_changes']) > 5:
                    entry += f"- ... et {len(execution_data['versioning']['significant_changes']) - 5} autres\n"
                entry += "\n"
        
        # Top marques par nombre de mod√®les (top 10)
        sorted_brands = sorted(
            execution_data['brands_data'].items(),
            key=lambda x: len(x[1]),
            reverse=True
        )[:10]
        
        entry += "### üèÜ Top 10 Marques (par nombre de mod√®les)\n\n"
        for i, (brand, models) in enumerate(sorted_brands, 1):
            entry += f"{i}. **{brand}** - {len(models)} mod√®les\n"
        entry += "\n"
        
        # D√©tail des nouvelles marques importantes (si en mode test, pas toutes)
        if execution_data.get('versioning', {}).get('new_brands') and execution_data['total_brands'] <= 50:
            entry += "### üÜï D√©tail des Nouvelles Marques\n\n"
            for brand in execution_data['versioning']['new_brands']:
                models = execution_data['brands_data'].get(brand, [])
                entry += f"**{brand}** ({len(models)} mod√®les) :\n"
                for model in sorted(models)[:5]:  # Limiter √† 5 mod√®les par marque
                    entry += f"- {model}\n"
                if len(models) > 5:
                    entry += f"- ... et {len(models) - 5} autres\n"
                entry += "\n"
        
        entry += "---\n\n"
        
        return entry
    
    def save_results(self, output_file=None):
        """Sauvegarde les r√©sultats avec versioning automatique et version Markdown."""
        try:
            if not output_file:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_file = f"data/as24_scraped_models_{timestamp}.json"
            
            # Pr√©parer les donn√©es
            result_data = {
                "metadata": {
                    "scraped_at": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "scraper_version": "v3.3_autonomous_with_history_and_markdown",
                    "source": "AutoScout24.fr Auto Scraping",
                    "method": "selenium_dynamic_dropdown_interaction",
                    "total_brands": len(self.brand_models_data),
                    "total_models": sum(len(models) for models in self.brand_models_data.values()),
                    "brands_with_models": len([b for b, models in self.brand_models_data.items() if models]),
                    "brands_without_models": len([b for b, models in self.brand_models_data.items() if not models])
                },
                "brands_models": self.brand_models_data
            }
            
            # Sauvegarder le fichier JSON
            Path(output_file).parent.mkdir(parents=True, exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, indent=2, ensure_ascii=False)
            
            # G√©n√©rer la version Markdown
            md_file = self.generate_markdown_version(result_data, output_file)
            
            logger.info(f"üíæ R√©sultats sauvegard√©s:")
            logger.info(f"   üìÑ JSON: {output_file}")
            logger.info(f"   üìù MD: {md_file}")
            
            # R√©sum√© final avec versioning
            total_models = result_data["metadata"]["total_models"]
            brands_with_models = result_data["metadata"]["brands_with_models"]
            
            # Rapport de versioning final
            versioning_data = self.generate_versioning_report(result_data)
            
            # Mettre √† jour l'historique Markdown
            self.update_execution_history(output_file, versioning_data)
            
            logger.info("üìä R√âSUM√â FINAL:")
            logger.info(f"   ‚Ä¢ Marques trait√©es: {len(self.brand_models_data)}")
            logger.info(f"   ‚Ä¢ Marques avec mod√®les: {brands_with_models}")
            logger.info(f"   ‚Ä¢ Total mod√®les: {total_models}")
            
            return output_file
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde: {e}")
            return None
    
    def generate_markdown_version(self, result_data, json_file_path):
        """G√©n√®re une version Markdown lisible des donn√©es."""
        try:
            # Cr√©er le chemin du fichier Markdown
            json_path = Path(json_file_path)
            md_file = json_path.with_suffix('.md')
            
            # Pr√©parer le contenu Markdown
            md_content = self.format_data_as_markdown(result_data)
            
            # Sauvegarder le fichier Markdown
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(md_content)
            
            logger.info(f"üìù Fichier Markdown g√©n√©r√©: {md_file}")
            return str(md_file)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration du fichier Markdown: {e}")
            return None
    
    def format_data_as_markdown(self, result_data):
        """Formate les donn√©es en Markdown lisible."""
        try:
            metadata = result_data["metadata"]
            brands_models = result_data["brands_models"]
            
            # En-t√™te
            md_content = f"""# üöó AutoScout24 - Marques et Mod√®les

**Fichier g√©n√©r√© le** : {metadata['scraped_at']}  
**Scraper** : {metadata['scraper_version']}  
**Source** : {metadata['source']}  
**M√©thode** : {metadata['method']}  

## üìä Statistiques Globales

- **üìã Marques trait√©es** : {metadata['total_brands']}
- **‚úÖ Marques avec mod√®les** : {metadata['brands_with_models']}
- **‚ùå Marques sans mod√®les** : {metadata['brands_without_models']}
- **üè∑Ô∏è Total mod√®les** : {metadata['total_models']}

---

## üìã Liste Compl√®te des Marques et Mod√®les

"""

            # Trier les marques alphab√©tiquement
            sorted_brands = sorted(brands_models.items())
            
            for brand_name, models in sorted_brands:
                if models:  # Seulement les marques avec des mod√®les
                    md_content += f"### {brand_name}\n\n"
                    md_content += f"**{len(models)} mod√®les** :\n\n"
                    
                    # Trier les mod√®les pour chaque marque
                    sorted_models = sorted(models)
                    
                    # Organiser en colonnes pour une meilleure lisibilit√©
                    if len(sorted_models) <= 10:
                        # Si peu de mod√®les, les afficher en ligne
                        md_content += "‚Ä¢ " + "\n‚Ä¢ ".join(sorted_models) + "\n\n"
                    else:
                        # Si beaucoup de mod√®les, les organiser en colonnes
                        md_content += "| Colonne 1 | Colonne 2 | Colonne 3 |\n"
                        md_content += "|-----------|-----------|----------|\n"
                        
                        # Remplir les colonnes
                        for i in range(0, len(sorted_models), 3):
                            col1 = sorted_models[i] if i < len(sorted_models) else ""
                            col2 = sorted_models[i+1] if i+1 < len(sorted_models) else ""
                            col3 = sorted_models[i+2] if i+2 < len(sorted_models) else ""
                            md_content += f"| {col1} | {col2} | {col3} |\n"
                        md_content += "\n"
            
            # Section des marques sans mod√®les (si il y en a)
            brands_without_models = [brand for brand, models in brands_models.items() if not models]
            if brands_without_models:
                md_content += f"\n## ‚ùå Marques Sans Mod√®les ({len(brands_without_models)})\n\n"
                for brand in sorted(brands_without_models):
                    md_content += f"- {brand}\n"
                md_content += "\n"
            
            # Top marques par nombre de mod√®les
            md_content += "## üèÜ Top 15 Marques (par nombre de mod√®les)\n\n"
            sorted_by_models = sorted(
                [(brand, len(models)) for brand, models in brands_models.items() if models],
                key=lambda x: x[1],
                reverse=True
            )[:15]
            
            for i, (brand, model_count) in enumerate(sorted_by_models, 1):
                md_content += f"{i}. **{brand}** - {model_count} mod√®les\n"
            
            # R√©partition par nombre de mod√®les
            model_counts = [len(models) for models in brands_models.values() if models]
            if model_counts:
                md_content += "\n## üìà R√©partition du Nombre de Mod√®les\n\n"
                from collections import Counter
                count_distribution = Counter(model_counts)
                
                for model_count in sorted(count_distribution.keys(), reverse=True):
                    brand_count = count_distribution[model_count]
                    md_content += f"- **{model_count} mod√®les** : {brand_count} marque{'s' if brand_count > 1 else ''}\n"
            
            # Pied de page
            md_content += f"\n---\n\n"
            md_content += f"**Fichier source** : `as24_scraped_models_{metadata['scraped_at'].replace(':', '').replace('-', '').replace('T', '_')}.json`\n"
            md_content += f"**G√©n√©r√© par** : AutoScout24 Scraper {metadata['scraper_version']}\n"
            md_content += f"**Date de g√©n√©ration** : {datetime.now().strftime('%d/%m/%Y √† %H:%M:%S')}\n"
            
            return md_content
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du formatage Markdown: {e}")
            return f"# üöó AutoScout24 - Marques et Mod√®les\n\n**Erreur lors du formatage :** {e}\n"

    def generate_brands_markdown_version(self, brands_data, json_file_path):
        """G√©n√®re une version Markdown lisible des marques extraites."""
        try:
            # Cr√©er le chemin du fichier Markdown
            json_path = Path(json_file_path)
            md_file = json_path.with_suffix('.md')

            # Pr√©parer le contenu Markdown
            md_content = self.format_brands_as_markdown(brands_data)

            # Sauvegarder le fichier Markdown
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(md_content)

            logger.info(f"üìù Fichier Markdown des marques g√©n√©r√©: {md_file}")
            return str(md_file)

        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration du fichier Markdown des marques: {e}")
            return None

    def format_brands_as_markdown(self, brands_data):
        """Formate les donn√©es des marques en Markdown lisible."""
        try:
            metadata = brands_data["metadata"]
            brands_list = brands_data["brands"]

            # En-t√™te
            md_content = f"""# üöó AutoScout24 - Liste des Marques Disponibles

**Fichier g√©n√©r√© le** : {metadata['extracted_at']}
**Source** : {metadata['source']}
**M√©thode** : {metadata['method']}

## üìä Statistiques

- **üìã Marques extraites** : {metadata['total_brands']}
- **üîç Provenance** : Menu d√©roulant AutoScout24.fr

---

## üìã Liste Compl√®te des Marques

"""

            # Trier les marques alphab√©tiquement
            sorted_brands = sorted(brands_list, key=lambda x: x['name'])

            # Organiser en colonnes pour une meilleure lisibilit√©
            md_content += "| Marque | ID |\n"
            md_content += "|--------|----|\n"

            for brand in sorted_brands:
                md_content += f"| {brand['name']} | `{brand['id']}` |\n"

            md_content += "\n"

            # Section des statistiques suppl√©mentaires
            md_content += "## üìà Analyse des Marques\n\n"

            # R√©partition par premi√®re lettre
            from collections import defaultdict
            letter_distribution = defaultdict(int)
            for brand in brands_list:
                first_letter = brand['name'][0].upper()
                letter_distribution[first_letter] += 1

            md_content += "### R√©partition par Premi√®re Lettre\n\n"
            sorted_letters = sorted(letter_distribution.items())
            for letter, count in sorted_letters:
                md_content += f"- **{letter}** : {count} marque{'s' if count > 1 else ''}\n"

            # Top marques par longueur de nom
            md_content += "\n### Marques avec Noms les Plus Longs\n\n"
            longest_names = sorted(brands_list, key=lambda x: len(x['name']), reverse=True)[:10]
            for brand in longest_names:
                md_content += f"- **{brand['name']}** ({len(brand['name'])} caract√®res)\n"

            # Pied de page
            md_content += f"\n---\n\n"
            md_content += f"**Fichier source** : `as24_brands_for_scraping.json`\n"
            md_content += f"**G√©n√©r√© par** : AutoScout24 Scraper v{metadata.get('scraper_version', '3.3')}\n"
            md_content += f"**Date de g√©n√©ration** : {datetime.now().strftime('%d/%m/%Y √† %H:%M:%S')}\n"

            return md_content

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du formatage Markdown des marques: {e}")
            return f"# üöó AutoScout24 - Liste des Marques\n\n**Erreur lors du formatage :** {e}\n"
    
    def generate_versioning_report(self, current_data):
        """G√©n√®re un rapport d√©taill√© de versioning et retourne les donn√©es pour l'historique."""
        try:
            # Chercher le fichier de donn√©es le plus r√©cent (sauf le fichier actuel)
            data_dir = Path("data")
            version_pattern = r"as24_scraped_models_(\d{8}_\d{6})\.json"
            
            versions = []
            for file in data_dir.glob("as24_scraped_models_*.json"):
                match = re.search(version_pattern, file.name)
                if match:
                    timestamp = match.group(1)
                    versions.append((timestamp, file))
            
            if len(versions) < 2:
                logger.info("‚ÑπÔ∏è Premi√®re ex√©cution - aucun rapport de versioning")
                return {}
            
            # Trouver la version pr√©c√©dente (pas la plus r√©cente, mais l'avant-derni√®re)
            versions.sort(key=lambda x: x[0])
            previous_file = versions[-2][1]  # L'avant-derni√®re version
            
            logger.info(f"üîÑ Rapport de versioning vs {previous_file.name}")
            
            # Charger la version pr√©c√©dente
            with open(previous_file, 'r', encoding='utf-8') as f:
                previous_data = json.load(f)
            
            # Comparaisons globales
            previous_brands_count = len(previous_data["brands_models"])
            current_brands_count = len(current_data["brands_models"])
            brand_change = current_brands_count - previous_brands_count
            
            previous_models_count = sum(len(models) for models in previous_data["brands_models"].values())
            current_models_count = sum(len(models) for models in current_data["brands_models"].values())
            models_change = current_models_count - previous_models_count
            
            logger.info("üìä COMPARAISON GLOBALE:")
            logger.info(f"   ‚Ä¢ Marques: {previous_brands_count} ‚Üí {current_brands_count} ({brand_change:+d})")
            logger.info(f"   ‚Ä¢ Mod√®les: {previous_models_count} ‚Üí {current_models_count} ({models_change:+d})")
            
            # D√©tail des marques
            previous_brands = set(previous_data["brands_models"].keys())
            current_brands = set(current_data["brands_models"].keys())
            
            new_brands = current_brands - previous_brands
            removed_brands = previous_brands - current_brands
            
            if new_brands:
                logger.info(f"   ‚Ä¢ NOUVELLES MARQUES ({len(new_brands)}):")
                for brand in sorted(new_brands):
                    model_count = len(current_data["brands_models"][brand])
                    logger.info(f"     + {brand} ({model_count} mod√®les)")
            
            if removed_brands:
                logger.info(f"   ‚Ä¢ MARQUES SUPPRIM√âES ({len(removed_brands)}):")
                for brand in sorted(removed_brands):
                    logger.info(f"     - {brand}")
            
            # Marques avec changements de mod√®les significatifs
            significant_changes = []
            for brand in previous_brands & current_brands:
                previous_models = set(previous_data["brands_models"][brand])
                current_models = set(current_data["brands_models"][brand])
                
                if len(previous_models ^ current_models) >= 3:  # Au moins 3 changements
                    previous_count = len(previous_models)
                    current_count = len(current_models)
                    significant_changes.append({
                        "brand": brand,
                        "previous_count": previous_count,
                        "current_count": current_count,
                        "change": current_count - previous_count
                    })
            
            if significant_changes:
                logger.info(f"   ‚Ä¢ MARQUES AVEC CHANGEMENTS SIGNIFICATIFS ({len(significant_changes)}):")
                for change in sorted(significant_changes, key=lambda x: abs(x['change']), reverse=True)[:5]:  # Top 5
                    logger.info(f"     ~ {change['brand']}: {change['previous_count']} ‚Üí {change['current_count']} mod√®les")
                if len(significant_changes) > 5:
                    logger.info(f"     ... et {len(significant_changes) - 5} autres")
            
            logger.info("üìÅ Fichier de comparaison disponible pour analyse d√©taill√©e")
            
            # Pr√©parer les donn√©es pour l'historique
            return {
                "previous_brands": previous_brands_count,
                "current_brands": current_brands_count,
                "brand_changes": brand_change,
                "previous_models": previous_models_count,
                "current_models": current_models_count,
                "model_changes": models_change,
                "new_brands": list(new_brands),
                "removed_brands": list(removed_brands),
                "significant_changes": significant_changes
            }
            
        except Exception as e:
            logger.debug(f"Erreur lors de la g√©n√©ration du rapport de versioning: {e}")
            return {}
    
    def scrape_all_brands(self, max_brands=None):
        """Scrape toutes les marques de la liste JSON."""
        try:
            if not self.navigate_to_homepage():
                return False
            
            # D√©terminer les marques √† traiter
            brands_to_process = self.brands_list[:max_brands] if max_brands else self.brands_list
            logger.info(f"üöÄ D√©but du scraping pour {len(brands_to_process)} marques")
            
            for i, brand_info in enumerate(brands_to_process, 1):
                brand_name = brand_info["name"]
                brand_id = brand_info["id"]
                
                logger.info(f"üè∑Ô∏è [{i}/{len(brands_to_process)}] {brand_name}")
                
                try:
                    models = self.scrape_brand_models(brand_name, brand_id)
                    self.brand_models_data[brand_name] = models
                    
                    # Comparer avec la version pr√©c√©dente pour cette marque
                    model_changes = self.compare_model_changes_with_previous(brand_name, models)
                    
                    if models:
                        logger.info(f"   ‚úÖ {len(models)} mod√®les")
                        if model_changes and model_changes["total_changes"] > 0:
                            logger.info(f"   üîÑ Changements: +{len(model_changes['new_models'])} -{len(model_changes['removed_models'])}")
                    else:
                        logger.warning(f"   ‚ö†Ô∏è Aucun mod√®le")
                    
                except Exception as e:
                    logger.error(f"   ‚ùå Erreur: {e}")
                    self.brand_models_data[brand_name] = []
                
                # Pause entre les marques (2-4 secondes)
                time.sleep(random.uniform(2, 4))
                
                # Afficher le progr√®s tous les 10 marques
                if i % 10 == 0:
                    brands_with_models = len([b for b, models in self.brand_models_data.items() if models])
                    logger.info(f"üìä Progr√®s: {i}/{len(brands_to_process)} marques, {brands_with_models} avec mod√®les")
            
            logger.info(f"üéâ Scraping termin√©! {len(self.brand_models_data)} marques trait√©es")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du scraping: {e}")
            return False
    
    def close(self):
        """Ferme le driver proprement."""
        if hasattr(self, 'driver'):
            self.driver.quit()
            logger.info("üîí Driver ferm√©")

def main():
    """Fonction principale avec gestion d'arguments."""
    parser = argparse.ArgumentParser(
        description="AutoScout24 Scraper Autonome - Extrait les mod√®les par marque avec historique",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  python autoscout24_scraper.py                 # Toutes les marques (extraction auto si n√©cessaire)
  python autoscout24_scraper.py --test          # Test rapide (20 marques)
  python autoscout24_scraper.py --max-brands 50 # 50 marques maximum
  python autoscout24_scraper.py --headless=False # Voir le navigateur
        """
    )
    
    parser.add_argument('--test', action='store_true', 
                       help='Mode test (20 marques seulement)')
    parser.add_argument('--max-brands', type=int, metavar='N',
                       help='Limiter le nombre de marques √† scraper')
    parser.add_argument('--headless', action='store_true', default=True,
                       help='Mode headless (d√©faut: True)')
    parser.add_argument('--no-headless', dest='headless', action='store_false',
                       help='Afficher le navigateur')
    
    args = parser.parse_args()
    
    # D√©terminer les param√®tres
    max_brands = 20 if args.test else args.max_brands
    
    logger.info("üöÄ AutoScout24 Scraper Autonome - Version 3.3 avec Historique et Markdown")
    logger.info(f"   ‚Ä¢ Mode: {'Test' if args.test else 'Complet'}")
    logger.info(f"   ‚Ä¢ Headless: {args.headless}")
    logger.info(f"   ‚Ä¢ Marques max: {max_brands or 'Toutes'}")
    logger.info("   ‚Ä¢ üöÄ Extraction automatique des marques si n√©cessaire")
    logger.info("   ‚Ä¢ üìä Rapport de versioning automatique")
    logger.info("   ‚Ä¢ üìù Historique Markdown automatique")
    
    try:
        scraper = AutoScout24Scraper(headless=args.headless)
        
        # Lancer le scraping
        success = scraper.scrape_all_brands(max_brands=max_brands)
        
        if success:
            output_file = scraper.save_results()
            if output_file:
                logger.info(f"üéâ SUCCESS! Fichier g√©n√©r√©: {output_file}")
                logger.info(f"üìù Historique disponible: docs/execution_history.md")
            else:
                logger.error("‚ùå Erreur lors de la sauvegarde")
        else:
            logger.error("‚ùå √âchec du scraping")
        
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è Interruption par l'utilisateur")
        if 'scraper' in locals():
            scraper.save_results()
    except Exception as e:
        logger.error(f"üí• Erreur g√©n√©rale: {e}")
    finally:
        if 'scraper' in locals():
            scraper.close()

if __name__ == "__main__":
    main()